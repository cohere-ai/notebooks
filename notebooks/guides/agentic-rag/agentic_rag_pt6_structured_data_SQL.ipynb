{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/cohere-ai/notebooks/blob/main/notebooks/guides/agentic-rag/agentic_rag_pt6_structured_data_SQL.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Querying Structured Data (SQL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous tutorial, we explored how agentic RAG can handle complex queries on structured data in the form of tables using pandas. Now, we'll see how we can do the same for SQL databases.\n",
    "\n",
    "Consider a scenario similar to the previous tutorial where we have evaluation results for an LLM application. However, instead of a CSV file, this data is now stored in a SQLite database. Users might still ask questions like \"What's the average score for a specific use case?\" or \"Which configuration has the lowest latency?\", but now we'll answer these using SQL queries instead of pandas operations.\n",
    "\n",
    "In this tutorial, we'll cover:\n",
    "- Setting up a SQLite database\n",
    "- Creating a function to execute SQL queries\n",
    "- Building an agent for querying SQL databases\n",
    "- Running the agent with various types of queries\n",
    "\n",
    "By implementing these techniques, we'll expand our agentic RAG system to handle structured data in SQL databases, complementing our previous work with tabular data in pandas.\n",
    "\n",
    "Let's get started by setting up our environment and creating our SQLite database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "To get started, first we need to install the `cohere` library and create a Cohere client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import cohere\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "co = cohere.ClientV2(api_key=os.environ[\"COHERE_API_KEY\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a SQLite database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll create a SQLite database to store our evaluation results. SQLite is a lightweight, serverless database engine that's perfect for small to medium-sized applications. Here's what we're going to do:\n",
    "\n",
    "1. Create a new SQLite database file named `evaluation_results.db`.\n",
    "2. Create a table called `evaluation_results` with columns for `usecase`, `run`, `score`, `temperature`, `tokens`, and `latency`.\n",
    "3. Insert sample data into the table to simulate our evaluation results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a connection to a new SQLite database (or connect to an existing one)\n",
    "conn = sqlite3.connect('evaluation_results.db')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Execute the CREATE TABLE command\n",
    "cursor.execute('''\n",
    "CREATE TABLE evaluation_results (\n",
    "    usecase TEXT,\n",
    "    run TEXT,\n",
    "    score FLOAT,\n",
    "    temperature FLOAT,\n",
    "    tokens INTEGER,\n",
    "    latency FLOAT\n",
    ")\n",
    "''')\n",
    "\n",
    "# Execute the INSERT commands\n",
    "data = [\n",
    "    ('extract_names', 'A', 0.5, 0.3, 103, 1.12),\n",
    "    ('draft_email', 'A', 0.6, 0.3, 252, 2.5),\n",
    "    ('summarize_article', 'A', 0.8, 0.3, 350, 4.2),\n",
    "    ('extract_names', 'B', 0.2, 0.3, 101, 2.85),\n",
    "    ('draft_email', 'B', 0.4, 0.3, 230, 3.2),\n",
    "    ('summarize_article', 'B', 0.6, 0.3, 370, 4.2),\n",
    "    ('extract_names', 'C', 0.7, 0.3, 101, 2.22),\n",
    "    ('draft_email', 'C', 0.5, 0.3, 221, 2.5),\n",
    "    ('summarize_article', 'C', 0.1, 0.3, 361, 3.9),\n",
    "    ('extract_names', 'D', 0.7, 0.5, 120, 3.2),\n",
    "    ('draft_email', 'D', 0.8, 0.5, 280, 3.4),\n",
    "    ('summarize_article', 'D', 0.9, 0.5, 342, 4.8)\n",
    "]\n",
    "\n",
    "cursor.executemany('INSERT INTO evaluation_results VALUES (?,?,?,?,?,?)', data)\n",
    "\n",
    "# Commit the changes and close the connection\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a function to query a SQL database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll define a function called `sql_table_query` that allows us to execute SQL queries on our evaluation_results database.\n",
    "\n",
    "This function will enable us to retrieve and analyze data from our evaluation_results table, allowing for dynamic querying based on our specific needs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sql_table_query(query: str) -> dict:\n",
    "    \"\"\"\n",
    "    Execute an SQL query on the evaluation_results table and return the result as a dictionary.\n",
    "    \n",
    "    Args:\n",
    "    query (str): SQL query to execute on the evaluation_results table\n",
    "    \n",
    "    Returns:\n",
    "    dict: Result of the SQL query\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Connect to the SQLite database\n",
    "        conn = sqlite3.connect('evaluation_results.db')\n",
    "        \n",
    "        # Execute the query and fetch the results into a DataFrame\n",
    "        df = pd.read_sql_query(query, conn)\n",
    "        \n",
    "        # Close the connection\n",
    "        conn.close()\n",
    "        \n",
    "        # Convert DataFrame to dictionary\n",
    "        result_dict = df.to_dict(orient='records')\n",
    "        \n",
    "        return result_dict\n",
    "    \n",
    "    except sqlite3.Error as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return str(e)\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "        return str(e)\n",
    "    \n",
    "functions_map = {\n",
    "    \"sql_table_query\": sql_table_query\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can test the function by running a simple query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'usecase': 'extract_names', 'run': 'A', 'score': 0.5, 'temperature': 0.3, 'tokens': 103, 'latency': 1.12}, {'usecase': 'extract_names', 'run': 'B', 'score': 0.2, 'temperature': 0.3, 'tokens': 101, 'latency': 2.85}, {'usecase': 'extract_names', 'run': 'C', 'score': 0.7, 'temperature': 0.3, 'tokens': 101, 'latency': 2.22}, {'usecase': 'extract_names', 'run': 'D', 'score': 0.7, 'temperature': 0.5, 'tokens': 120, 'latency': 3.2}]\n"
     ]
    }
   ],
   "source": [
    "result = sql_table_query(\"SELECT * FROM evaluation_results WHERE usecase = 'extract_names'\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up a tool to interact with the database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll create a tool that will allow the agent to interact with the SQLite database containing our evaluation results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_table_query_tool = {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"sql_table_query\",\n",
    "            \"description\": \"Execute an SQL query on the evaluation_results table in the SQLite database. The table has columns 'usecase', 'run', 'score', 'temperature', 'tokens', and 'latency'.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"query\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"SQL query to execute on the evaluation_results table\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"query\"]\n",
    "            }\n",
    "        }\n",
    "}\n",
    "\n",
    "tools = [sql_table_query_tool]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building an agent for querying SQL data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's create a `run_agent` function to run the agentic RAG workflow, the same as in Part 1.\n",
    "\n",
    "The only change we are making here is to make the system message more specific and describe the database schema to the agent.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message=\"\"\"## Task and Context\n",
    "You are an assistant who helps developers analyze LLM application evaluation results from a SQLite database. The database contains a table named 'evaluation_results' with the following schema:\n",
    "\n",
    "- usecase (TEXT): The type of task being evaluated\n",
    "- run (TEXT): The identifier for a specific evaluation run\n",
    "- score (REAL): The performance score of the run\n",
    "- temperature (REAL): The temperature setting used for the LLM\n",
    "- tokens (INTEGER): The number of tokens used in the run\n",
    "- latency (REAL): The time taken for the run in seconds\n",
    "\n",
    "You can use SQL queries to analyze this data and provide insights to the developers.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"command-r-plus-08-2024\"\n",
    "\n",
    "def run_agent(query, messages=None):\n",
    "    if messages is None:\n",
    "        messages = []\n",
    "        \n",
    "    if \"system\" not in {m.get(\"role\") for m in messages}:\n",
    "        messages.append({\"role\": \"system\", \"content\": system_message})\n",
    "    \n",
    "    # Step 1: get user message\n",
    "    print(f\"Question:\\n{query}\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    messages.append({\"role\": \"user\", \"content\": query})\n",
    "\n",
    "    # Step 2: Generate tool calls (if any)\n",
    "    response = co.chat(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        tools=tools,\n",
    "        temperature=0.1\n",
    "    )\n",
    "\n",
    "    while response.message.tool_calls:\n",
    "        \n",
    "        print(\"Tool plan:\")\n",
    "        print(response.message.tool_plan,\"\\n\")\n",
    "        print(\"Tool calls:\")\n",
    "        for tc in response.message.tool_calls:\n",
    "            # print(f\"Tool name: {tc.function.name} | Parameters: {tc.function.arguments}\")\n",
    "            if tc.function.name == \"analyze_evaluation_results\":\n",
    "                print(f\"Tool name: {tc.function.name}\")\n",
    "                tool_call_prettified = print(\"\\n\".join(f\"  {line}\" for line_num, line in enumerate(json.loads(tc.function.arguments)[\"code\"].splitlines())))\n",
    "                print(tool_call_prettified)\n",
    "            else:\n",
    "                print(f\"Tool name: {tc.function.name} | Parameters: {tc.function.arguments}\")\n",
    "        print(\"=\"*50)\n",
    "\n",
    "        messages.append({\"role\": \"assistant\", \"tool_calls\": response.message.tool_calls, \"tool_plan\": response.message.tool_plan})        \n",
    "        \n",
    "        # Step 3: Get tool results\n",
    "        for tc in response.message.tool_calls:\n",
    "            tool_result = functions_map[tc.function.name](**json.loads(tc.function.arguments))\n",
    "            tool_content = [({\"type\": \"document\", \"document\": {\"data\": json.dumps(tool_result)}})]\n",
    "                \n",
    "            messages.append({\"role\": \"tool\", \"tool_call_id\": tc.id, \"content\": tool_content})\n",
    "        \n",
    "        # Step 4: Generate response and citations \n",
    "        response = co.chat(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "            tools=tools,\n",
    "            temperature=0.1\n",
    "        )\n",
    "    \n",
    "    messages.append({\"role\": \"assistant\", \"content\": response.message.content[0].text})\n",
    "        \n",
    "    # Print final response\n",
    "    print(\"Response:\")\n",
    "    print(response.message.content[0].text)\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Print citations (if any)\n",
    "    verbose_source = False # Change to True to display the contents of a source\n",
    "    if response.message.citations:\n",
    "        print(\"CITATIONS:\\n\")\n",
    "        for citation in response.message.citations:\n",
    "            print(f\"Start: {citation.start}| End:{citation.end}| Text:'{citation.text}' \")\n",
    "            print(\"Sources:\")\n",
    "            for idx, source in enumerate(citation.sources):\n",
    "                print(f\"{idx+1}. {source.id}\")\n",
    "                if verbose_source:\n",
    "                    print(f\"{source.tool_output}\")\n",
    "            print(\"\\n\")\n",
    "    \n",
    "    return messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now ask the agent the same set of questions we asked in the previous chapter. While the previous chapter translates the questions into pandas Python code, this time the agent will be using SQL queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:\n",
      "What's the average evaluation score in run A\n",
      "==================================================\n",
      "Tool plan:\n",
      "I will write a SQL query to find the average evaluation score in run A. \n",
      "\n",
      "Tool calls:\n",
      "Tool name: sql_table_query | Parameters: {\"query\":\"SELECT AVG(score) FROM evaluation_results WHERE run = 'A'\"}\n",
      "==================================================\n",
      "Response:\n",
      "The average evaluation score in run A is **0.63**.\n",
      "==================================================\n",
      "CITATIONS:\n",
      "\n",
      "Start: 43| End:47| Text:'0.63' \n",
      "Sources:\n",
      "1. sql_table_query_jm4e5yp0ptad:0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "messages = run_agent(\"What's the average evaluation score in run A\")\n",
    "# Answer: 0.63"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:\n",
      "What's the latency of the highest-scoring run for the summarize_article use case?\n",
      "==================================================\n",
      "Tool plan:\n",
      "I will write and execute a SQL query to find the latency of the highest-scoring run for the summarize_article use case. \n",
      "\n",
      "Tool calls:\n",
      "Tool name: sql_table_query | Parameters: {\"query\":\"SELECT latency FROM evaluation_results WHERE usecase = 'summarize_article' ORDER BY score DESC LIMIT 1\"}\n",
      "==================================================\n",
      "Response:\n",
      "The latency of the highest-scoring run for the summarize_article use case is 4.8 seconds.\n",
      "==================================================\n",
      "CITATIONS:\n",
      "\n",
      "Start: 77| End:89| Text:'4.8 seconds.' \n",
      "Sources:\n",
      "1. sql_table_query_mxyzvcnsgdab:0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "messages = run_agent(\"What's the latency of the highest-scoring run for the summarize_article use case?\")\n",
    "# Answer: 4.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:\n",
      "Which use case uses the least amount of tokens on average? Show the comparison of all use cases in a markdown table.\n",
      "==================================================\n",
      "Tool plan:\n",
      "I will use the SQL tool to query the database for the average number of tokens used for each use case. I will then use the directly_answer tool to present the results in a markdown table. \n",
      "\n",
      "Tool calls:\n",
      "Tool name: sql_table_query | Parameters: {\"query\":\"SELECT usecase, AVG(tokens) as avg_tokens FROM evaluation_results GROUP BY usecase ORDER BY avg_tokens ASC\"}\n",
      "==================================================\n",
      "Response:\n",
      "The use case that uses the least amount of tokens on average is `extract_names`, with an average of 106.25 tokens. Here's a table comparing the average number of tokens used for all use cases:\n",
      "\n",
      "| Use Case | Average Tokens |\n",
      "|---|---|\n",
      "| `extract_names` | 106.25 |\n",
      "| `draft_email` | 245.75 |\n",
      "| `summarize_article` | 355.75 |\n",
      "==================================================\n",
      "CITATIONS:\n",
      "\n",
      "Start: 64| End:114| Text:'`extract_names`, with an average of 106.25 tokens.' \n",
      "Sources:\n",
      "1. sql_table_query_2qyr8vpqrf2v:0\n",
      "\n",
      "\n",
      "Start: 236| End:250| Text:'`extract_names' \n",
      "Sources:\n",
      "1. sql_table_query_2qyr8vpqrf2v:0\n",
      "\n",
      "\n",
      "Start: 254| End:260| Text:'106.25' \n",
      "Sources:\n",
      "1. sql_table_query_2qyr8vpqrf2v:0\n",
      "\n",
      "\n",
      "Start: 265| End:277| Text:'`draft_email' \n",
      "Sources:\n",
      "1. sql_table_query_2qyr8vpqrf2v:0\n",
      "\n",
      "\n",
      "Start: 281| End:287| Text:'245.75' \n",
      "Sources:\n",
      "1. sql_table_query_2qyr8vpqrf2v:0\n",
      "\n",
      "\n",
      "Start: 292| End:310| Text:'`summarize_article' \n",
      "Sources:\n",
      "1. sql_table_query_2qyr8vpqrf2v:0\n",
      "\n",
      "\n",
      "Start: 314| End:320| Text:'355.75' \n",
      "Sources:\n",
      "1. sql_table_query_2qyr8vpqrf2v:0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "messages = run_agent(\"Which use case uses the least amount of tokens on average? Show the comparison of all use cases in a markdown table.\")\n",
    "# Answer: extract_names (106.25), draft_email (245.75), summarize_article (355.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this tutorial, we learned about:\n",
    "- How to set up a SQLite database for structured data\n",
    "- How to create a function to execute SQL queries\n",
    "- How to build an agent for querying the database\n",
    "- How to run the agent\n",
    "\n",
    "By implementing these techniques, we've further expanded our agentic RAG system to handle structured data in the form of SQL databases. This allows for more powerful and flexible querying capabilities, especially when dealing with large datasets or complex relationships between data.\n",
    "\n",
    "This tutorial completes our exploration of structured data handling in the agentic RAG system, covering both tabular data (using pandas) and relational databases (using SQL). These capabilities significantly enhance the system's ability to work with diverse data formats and structures.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
