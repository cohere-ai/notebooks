{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/cohere-ai/notebooks/blob/main/notebooks/guides/agentic-rag/agentic_rag_pt3_sequential.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performing Tasks Sequentially"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare two user queries to a RAG chatbot, \"What was Apple's revenue in 2023?\" and \"What was the revenue in of the most valuable company in the US in 2023?\".\n",
    "\n",
    "While the first query is straightforward to handle, the second query requires breaking down into two steps:\n",
    "1. Identify the most valuable company in the US in 2023\n",
    "2. Get the revenue of the company in 2023\n",
    "\n",
    "These steps need to happen in a sequence rather than all at once. This is because the information retrieved from the first step is required to inform the second step.\n",
    "\n",
    "This is an example of sequential reasoning. In this tutorial, you will learn how agentic RAG with Cohere handles sequential reasoning, and in particular:\n",
    "- Multi-step tool calling\n",
    "- Multi-step, parallel tool calling\n",
    "- Self-correction\n",
    "\n",
    "You'll learn these by building an agent that answers questions about using Cohere."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "To get started, first we need to install the `cohere` library and create a Cohere client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import cohere\n",
    "\n",
    "from tool_def import (\n",
    "    search_developer_docs,\n",
    "    search_developer_docs_tool,\n",
    "    search_internet,\n",
    "    search_internet_tool,\n",
    "    search_code_examples,\n",
    "    search_code_examples_tool,\n",
    ")\n",
    "\n",
    "co = cohere.ClientV2(api_key=os.environ[\"COHERE_API_KEY\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set up the same set of tools as in Part 1. If you want further details on how to set up the tools, check out Part 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions_map = {\n",
    "    \"search_developer_docs\": search_developer_docs,\n",
    "    \"search_internet\": search_internet,\n",
    "    \"search_code_examples\": search_code_examples,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running an agentic RAG workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a `run_agent` function to run the agentic RAG workflow, the same as in Part 1. If you want further details on how to set up the tools, check out Part 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    search_developer_docs_tool,\n",
    "    search_internet_tool,\n",
    "    search_code_examples_tool\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message=\"\"\"## Task and Context\n",
    "You are an assistant who helps developers use Cohere. You are equipped with a number of tools that can provide different types of information. If you can't find the information you need from one tool, you should try other tools if there is a possibility that they could provide the information you need.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"command-r-plus-08-2024\"\n",
    "\n",
    "def run_agent(query, messages=None):\n",
    "    if messages is None:\n",
    "        messages = []\n",
    "        \n",
    "    if \"system\" not in {m.get(\"role\") for m in messages}:\n",
    "        messages.append({\"role\": \"system\", \"content\": system_message})\n",
    "    \n",
    "    # Step 1: get user message\n",
    "    print(f\"QUESTION:\\n{query}\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    messages.append({\"role\": \"user\", \"content\": query})\n",
    "\n",
    "    # Step 2: Generate tool calls (if any)\n",
    "    response = co.chat(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        tools=tools,\n",
    "        temperature=0.1\n",
    "    )\n",
    "\n",
    "    while response.message.tool_calls:\n",
    "        \n",
    "        print(\"TOOL PLAN:\")\n",
    "        print(response.message.tool_plan,\"\\n\")\n",
    "        print(\"TOOL CALLS:\")\n",
    "        for tc in response.message.tool_calls:\n",
    "            print(f\"Tool name: {tc.function.name} | Parameters: {tc.function.arguments}\")\n",
    "        print(\"=\"*50)\n",
    "\n",
    "        messages.append({\"role\": \"assistant\", \"tool_calls\": response.message.tool_calls, \"tool_plan\": response.message.tool_plan})        \n",
    "        \n",
    "        # Step 3: Get tool results\n",
    "        for tc in response.message.tool_calls:\n",
    "            tool_result = functions_map[tc.function.name](**json.loads(tc.function.arguments))\n",
    "            tool_content = []\n",
    "            for data in tool_result:\n",
    "                tool_content.append({\"type\": \"document\", \"document\": {\"data\": json.dumps(data)}})\n",
    "                # Optional: add an \"id\" field in the \"document\" object, otherwise IDs are auto-generated\n",
    "            messages.append({\"role\": \"tool\", \"tool_call_id\": tc.id, \"content\": tool_content})\n",
    "        \n",
    "        # Step 4: Generate response and citations \n",
    "        response = co.chat(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "            tools=tools,\n",
    "            temperature=0.1\n",
    "        )\n",
    "    \n",
    "    messages.append({\"role\": \"assistant\", \"content\": response.message.content[0].text})\n",
    "        \n",
    "    # Print final response\n",
    "    print(\"RESPONSE:\")\n",
    "    print(response.message.content[0].text)\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Print citations (if any)\n",
    "    verbose_source = False # Change to True to display the contents of a source\n",
    "    if response.message.citations:\n",
    "        print(\"CITATIONS:\\n\")\n",
    "        for citation in response.message.citations:\n",
    "            print(f\"Start: {citation.start}| End:{citation.end}| Text:'{citation.text}' \")\n",
    "            print(\"Sources:\")\n",
    "            for idx, source in enumerate(citation.sources):\n",
    "                print(f\"{idx+1}. {source.id}\")\n",
    "                if verbose_source:\n",
    "                    print(f\"{source.tool_output}\")\n",
    "            print(\"\\n\")\n",
    "                    \n",
    "    return messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-step tool calling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's ask the agent a few questions, starting with this one about a specific feature. The user is asking about two things, first about a features to reorder search results, and second about code examples for that feature.\n",
    "\n",
    "In this case, the agent first needs to identify what that feature is before it can answer the second part of the question.\n",
    "\n",
    "This is reflected in the agent's tool plan, which describes the steps it will take to answer the question.\n",
    "\n",
    "So, it first calls the `search_developer_docs` tool to find the feature. \n",
    "\n",
    "It then finds out that the feature is Rerank. And using this information, it calls the `search_code_examples` tool to find code examples for that feature.\n",
    "\n",
    "Finally, it uses the retrieved information to answer both parts of the user's question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUESTION:\n",
      "What's the Cohere feature to reorder search results? Do you have any code examples on that?\n",
      "==================================================\n",
      "TOOL PLAN:\n",
      "I will search for the Cohere feature to reorder search results. Then I will search for code examples on that. \n",
      "\n",
      "TOOL CALLS:\n",
      "Tool name: search_developer_docs | Parameters: {\"query\":\"reorder search results\"}\n",
      "==================================================\n",
      "TOOL PLAN:\n",
      "I found that the Cohere feature to reorder search results is called the Rerank endpoint. I will now search for code examples on this. \n",
      "\n",
      "TOOL CALLS:\n",
      "Tool name: search_code_examples | Parameters: {\"query\":\"Rerank endpoint\"}\n",
      "==================================================\n",
      "RESPONSE:\n",
      "The Cohere feature to reorder search results is the Rerank endpoint. This endpoint takes in a query and a list of texts and produces an ordered array with each text assigned a relevance score.\n",
      "\n",
      "Here is a code example that uses the Rerank endpoint:\n",
      "\n",
      "RAG With Chat Embed and Rerank via Pinecone\n",
      "==================================================\n",
      "CITATIONS:\n",
      "\n",
      "Start: 52| End:68| Text:'Rerank endpoint.' \n",
      "Sources:\n",
      "1. search_developer_docs_07rw24b2sa29:0\n",
      "\n",
      "\n",
      "Start: 83| End:192| Text:'takes in a query and a list of texts and produces an ordered array with each text assigned a relevance score.' \n",
      "Sources:\n",
      "1. search_developer_docs_07rw24b2sa29:0\n",
      "\n",
      "\n",
      "Start: 249| End:292| Text:'RAG With Chat Embed and Rerank via Pinecone' \n",
      "Sources:\n",
      "1. search_code_examples_p6g6g21ev0re:2\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "messages = run_agent(\"What's the Cohere feature to reorder search results? Do you have any code examples on that?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-step, parallel tool calling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We saw in Part 2 how the Cohere API suports tool calling to happen in parallel, and now in a sequence. That also means that both scenarios can happen at the same time.\n",
    "\n",
    "Here's an examples. Suppose we ask the agent to find the leaders of the top 3 countries with the largest oil reserves.\n",
    "\n",
    "In the first step, it looks up the internet for information about the 3 countries with the largest oil reserves.\n",
    "\n",
    "And in the second step, it performs parallel searches for the leaders of the 3 identified countries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUESTION:\n",
      "Who are the leaders of the top 3 countries with the largest oil reserves.\n",
      "==================================================\n",
      "TOOL PLAN:\n",
      "I will search for the top 3 countries with the largest oil reserves. Then I will search for the leaders of each of these countries. \n",
      "\n",
      "TOOL CALLS:\n",
      "Tool name: search_internet | Parameters: {\"query\":\"top 3 countries with the largest oil reserves\"}\n",
      "==================================================\n",
      "TOOL PLAN:\n",
      "I have found that the top three countries with the largest oil reserves are Venezuela, Saudi Arabia and Canada. Now I need to find out who the leaders of these countries are. \n",
      "\n",
      "TOOL CALLS:\n",
      "Tool name: search_internet | Parameters: {\"query\":\"Who is the leader of Venezuela?\"}\n",
      "Tool name: search_internet | Parameters: {\"query\":\"Who is the leader of Saudi Arabia?\"}\n",
      "Tool name: search_internet | Parameters: {\"query\":\"Who is the leader of Canada?\"}\n",
      "==================================================\n",
      "RESPONSE:\n",
      "The top three countries with the largest oil reserves are Venezuela, Saudi Arabia, and Canada.\n",
      "\n",
      "The leader of Venezuela is Nicolás Maduro. Maduro was born on November 23, 1962, in Caracas, Venezuela. He won a special election in April 2013 to serve out the remainder of the term of Venezuelan President Hugo Chávez, who had died in March. Maduro, a former labor leader, became the interim president following Chávez's death.\n",
      "\n",
      "The leader of Saudi Arabia is Mohammed bin Salman. He was born on August 31, 1985, and is the eldest child of Salman bin Abdulaziz Al Saud and his third wife, Fahda bint Falah bin Sultan bin Hathleen al-Ajmi, the daughter of the head of a powerful Arabian tribe, known as the Al Ajman.\n",
      "\n",
      "The leader of Canada is Justin Trudeau. He was born on December 25, 1971, in Ottawa, Canada. He is the oldest son of former prime minister Pierre Trudeau and his wife, Margaret. Trudeau is the 23rd Prime Minister of Canada and the proud father of Xavier, Ella-Grace, and Hadrien.\n",
      "==================================================\n",
      "CITATIONS:\n",
      "\n",
      "Start: 58| End:67| Text:'Venezuela' \n",
      "Sources:\n",
      "1. search_internet_bf18bye7vnst:0\n",
      "2. search_internet_bf18bye7vnst:1\n",
      "3. search_internet_bf18bye7vnst:3\n",
      "\n",
      "\n",
      "Start: 69| End:81| Text:'Saudi Arabia' \n",
      "Sources:\n",
      "1. search_internet_bf18bye7vnst:0\n",
      "2. search_internet_bf18bye7vnst:1\n",
      "3. search_internet_bf18bye7vnst:3\n",
      "\n",
      "\n",
      "Start: 87| End:94| Text:'Canada.' \n",
      "Sources:\n",
      "1. search_internet_bf18bye7vnst:0\n",
      "2. search_internet_bf18bye7vnst:3\n",
      "\n",
      "\n",
      "Start: 123| End:138| Text:'Nicolás Maduro.' \n",
      "Sources:\n",
      "1. search_internet_m3014vh1k2sn:0\n",
      "2. search_internet_m3014vh1k2sn:1\n",
      "3. search_internet_m3014vh1k2sn:2\n",
      "4. search_internet_m3014vh1k2sn:3\n",
      "\n",
      "\n",
      "Start: 158| End:199| Text:'November 23, 1962, in Caracas, Venezuela.' \n",
      "Sources:\n",
      "1. search_internet_m3014vh1k2sn:0\n",
      "\n",
      "\n",
      "Start: 209| End:239| Text:'special election in April 2013' \n",
      "Sources:\n",
      "1. search_internet_m3014vh1k2sn:0\n",
      "\n",
      "\n",
      "Start: 303| End:314| Text:'Hugo Chávez' \n",
      "Sources:\n",
      "1. search_internet_m3014vh1k2sn:0\n",
      "\n",
      "\n",
      "Start: 324| End:338| Text:'died in March.' \n",
      "Sources:\n",
      "1. search_internet_m3014vh1k2sn:0\n",
      "\n",
      "\n",
      "Start: 349| End:368| Text:'former labor leader' \n",
      "Sources:\n",
      "1. search_internet_m3014vh1k2sn:0\n",
      "\n",
      "\n",
      "Start: 381| End:398| Text:'interim president' \n",
      "Sources:\n",
      "1. search_internet_m3014vh1k2sn:0\n",
      "\n",
      "\n",
      "Start: 456| End:476| Text:'Mohammed bin Salman.' \n",
      "Sources:\n",
      "1. search_internet_sph85190s567:1\n",
      "2. search_internet_sph85190s567:2\n",
      "3. search_internet_sph85190s567:3\n",
      "4. search_internet_sph85190s567:4\n",
      "\n",
      "\n",
      "Start: 492| End:507| Text:'August 31, 1985' \n",
      "Sources:\n",
      "1. search_internet_sph85190s567:2\n",
      "\n",
      "\n",
      "Start: 520| End:711| Text:'eldest child of Salman bin Abdulaziz Al Saud and his third wife, Fahda bint Falah bin Sultan bin Hathleen al-Ajmi, the daughter of the head of a powerful Arabian tribe, known as the Al Ajman.' \n",
      "Sources:\n",
      "1. search_internet_sph85190s567:2\n",
      "\n",
      "\n",
      "Start: 737| End:752| Text:'Justin Trudeau.' \n",
      "Sources:\n",
      "1. search_internet_b3xre9say1kk:0\n",
      "2. search_internet_b3xre9say1kk:1\n",
      "3. search_internet_b3xre9say1kk:2\n",
      "4. search_internet_b3xre9say1kk:3\n",
      "5. search_internet_b3xre9say1kk:4\n",
      "\n",
      "\n",
      "Start: 768| End:805| Text:'December 25, 1971, in Ottawa, Canada.' \n",
      "Sources:\n",
      "1. search_internet_b3xre9say1kk:0\n",
      "2. search_internet_b3xre9say1kk:2\n",
      "3. search_internet_b3xre9say1kk:4\n",
      "\n",
      "\n",
      "Start: 816| End:890| Text:'oldest son of former prime minister Pierre Trudeau and his wife, Margaret.' \n",
      "Sources:\n",
      "1. search_internet_b3xre9say1kk:4\n",
      "\n",
      "\n",
      "Start: 906| End:935| Text:'23rd Prime Minister of Canada' \n",
      "Sources:\n",
      "1. search_internet_b3xre9say1kk:0\n",
      "2. search_internet_b3xre9say1kk:1\n",
      "3. search_internet_b3xre9say1kk:2\n",
      "\n",
      "\n",
      "Start: 944| End:992| Text:'proud father of Xavier, Ella-Grace, and Hadrien.' \n",
      "Sources:\n",
      "1. search_internet_b3xre9say1kk:0\n",
      "2. search_internet_b3xre9say1kk:2\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "messages = run_agent(\"Who are the leaders of the top 3 countries with the largest oil reserves.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self-correction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The concept of sequential reasoning is useful in a broader sense, and in particular, where the agent needs to adapt and change its plan midway in a task. \n",
    "\n",
    "In other words, it allows the agent to self-correct.\n",
    "\n",
    "To illustrate this, let's look at an example. Here, the user is asking about the Cohere safety mode feature.\n",
    "\n",
    "Given the nature of the question, the agent correctly identifies that it needs to find required information via the `search_developer_docs` tool.\n",
    "\n",
    "However, we know that the tool doesn't contain this information because we have only added a small sample of documents there.\n",
    "\n",
    "As a result, the agent, having received the documents back without any relevant information, decides to search the internet instead. This is also helped by the fact the we have added specific instructions in the `search_internet` tool to search the internet for information not found in the developer documentation.\n",
    "\n",
    "It finally has the information it needs, and uses it to answer the user's question.\n",
    "\n",
    "This highlights another important aspect of agentic RAG where it allows a RAG system to be flexible. This is achieved by powering the retrieval component with an LLM.\n",
    "\n",
    "On the other hand, a standard RAG system would typically hand-engineer this, and hence, is more rigid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUESTION:\n",
      "How does the Cohere safety mode feature work.\n",
      "==================================================\n",
      "TOOL PLAN:\n",
      "I will search for 'How does the Cohere safety mode feature work?' \n",
      "\n",
      "TOOL CALLS:\n",
      "Tool name: search_developer_docs | Parameters: {\"query\":\"How does the Cohere safety mode feature work?\"}\n",
      "==================================================\n",
      "TOOL PLAN:\n",
      "I could not find any information about the Cohere safety mode feature in the developer documentation. I will now search the internet to see if I can find any information. \n",
      "\n",
      "TOOL CALLS:\n",
      "Tool name: search_internet | Parameters: {\"query\":\"How does the Cohere safety mode feature work?\"}\n",
      "==================================================\n",
      "RESPONSE:\n",
      "Cohere's Safety Modes aim to illustrate what model behaviours will look like under specific scenarios, thereby introducing a nuanced approach that is sensitive to context. By transparently communicating the strengths and boundaries of each mode, Cohere intends to set clear usage expectations while keeping safety as its top priority.\n",
      "\n",
      "Safety Modes work with Cohere's newest refreshed models, but not with older iterations. Users can switch between modes by simply adding the safety_mode parameter and choosing one of the options below.\n",
      "==================================================\n",
      "CITATIONS:\n",
      "\n",
      "Start: 29| End:101| Text:'illustrate what model behaviours will look like under specific scenarios' \n",
      "Sources:\n",
      "1. search_internet_64qs25r4ssd6:1\n",
      "\n",
      "\n",
      "Start: 125| End:171| Text:'nuanced approach that is sensitive to context.' \n",
      "Sources:\n",
      "1. search_internet_64qs25r4ssd6:1\n",
      "\n",
      "\n",
      "Start: 175| End:244| Text:'transparently communicating the strengths and boundaries of each mode' \n",
      "Sources:\n",
      "1. search_internet_64qs25r4ssd6:1\n",
      "\n",
      "\n",
      "Start: 264| End:292| Text:'set clear usage expectations' \n",
      "Sources:\n",
      "1. search_internet_64qs25r4ssd6:1\n",
      "\n",
      "\n",
      "Start: 299| End:334| Text:'keeping safety as its top priority.' \n",
      "Sources:\n",
      "1. search_internet_64qs25r4ssd6:1\n",
      "\n",
      "\n",
      "Start: 349| End:423| Text:'work with Cohere's newest refreshed models, but not with older iterations.' \n",
      "Sources:\n",
      "1. search_internet_64qs25r4ssd6:0\n",
      "\n",
      "\n",
      "Start: 424| End:536| Text:'Users can switch between modes by simply adding the safety_mode parameter and choosing one of the options below.' \n",
      "Sources:\n",
      "1. search_internet_64qs25r4ssd6:0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "messages = run_agent(\"How does the Cohere safety mode feature work.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this tutorial, you learned about:\n",
    "- How multi-step tool calling works\n",
    "- How multi-step, parallel tool calling works\n",
    "- How multi-step tool calling enables an agent to self-correct, and hence, be more flexible\n",
    "\n",
    "However, up till now, we have only worked with purely unstructured data, the type of data we typicallyencounter in a standard RAG system.\n",
    "\n",
    "In the coming chapters, we'll add another complexity to the agentic RAG system, which is working with semi-structured and structured data. This adds another dimension to the agent's flexibility, which is dealing with a more diverse set of data sources.\n",
    "\n",
    "In Part 4, you will learn how to work with semi-structured data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
