{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca57710c",
   "metadata": {},
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/cohere-ai/notebooks/blob/main/notebooks/llmu/Prompt_Engineering_Basics.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fac7165",
   "metadata": {},
   "source": [
    "# Prompt Engineering Basics\n",
    "\n",
    "Prompting is at the heart of working with LLMs. The prompt provides context for the text that we want the model to generate. The prompts we create can be anything from simple instructions to more complex pieces of text, and they are used to encourage the model to produce a specific type of output.\n",
    "\n",
    "Coming up with a good prompt is a bit of both science and art. On the one hand, we know the broad patterns that enable us to construct a prompt that will generate the output that we want. But on the other hand, there is so much room for creativity and imagination.\n",
    "\n",
    "In this notebook, you’ll learn how to craft effective prompts to obtain desirable outputs for various tasks.\n",
    "\n",
    "*Read the accompanying [article here](https://cohere.com/llmu/prompt-engineering-basics).*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834049c9",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7ec57f",
   "metadata": {},
   "source": [
    "The notebook is broken into 5 sections:\n",
    "- **How to Write a Basic Prompt** - Give the model commands with imperative verbs.\n",
    "- **How to Layer Additional Instructions** - Add additional instructions to be more precise about the desired about.\n",
    "- **How to Add Context to a Prompt** - Supply additional information as context to help ground the model's output.\n",
    "- **How to Extract Information** - Retrieve specific information from a larger body of text.\n",
    "- **How to Rewrite Text into Another Format** - Rewrite text (a passage of text) into another format (Q&A list)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b8bf51",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319754f5",
   "metadata": {},
   "source": [
    "We'll start by installing the tools we'll need and then importing them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a03e9387",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install cohere -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1a5060",
   "metadata": {},
   "source": [
    "Fill in your Cohere API key in the next cell. To do this, begin by [signing up to Cohere](https://os.cohere.ai/) (for free!) if you haven't yet. Then get your API key [here](https://dashboard.cohere.com/api-keys)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c465a580",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cohere\n",
    "co = cohere.ClientV2(\"COHERE_API_KEY\") # Get your free API key: https://dashboard.cohere.com/api-keys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0f9a08",
   "metadata": {},
   "source": [
    "Let's also define a function `generate_text()` to take a user message, call the Chat endpoint, and stream the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d4130e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(message):\n",
    "    # Generate the response by streaming it\n",
    "    response = co.chat_stream(model=\"command-r-plus-08-2024\",\n",
    "                   messages=[{'role':'user', 'content': message}])\n",
    "\n",
    "    for event in response:\n",
    "        if event.type == \"content-delta\":\n",
    "            print(event.delta.message.content.text, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d4b1c1",
   "metadata": {},
   "source": [
    "## How to Write a Basic Prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057daf26",
   "metadata": {},
   "source": [
    "The best way to design prompts for a model like [Command R/R+](https://cohere.com/models/command) is to give a command or an instruction. One way to do this is by using imperative verbs, for example: generate, write, list, provide, and other variations.\n",
    "\n",
    "For instance, let’s say that we are creating the product description copy for a wireless earbuds product. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3802a5b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Experience ultimate audio freedom with our sleek wireless earbuds. Immerse yourself in crystal-clear sound with powerful bass and noise-canceling technology. These lightweight earbuds offer a secure fit, long-lasting battery life, and seamless connectivity for an uninterrupted listening experience on the go.\""
     ]
    }
   ],
   "source": [
    "generate_text(\"Generate a concise product description for the product: wireless earbuds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801c9079",
   "metadata": {},
   "source": [
    "## How to Layer Additional Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0ee01b",
   "metadata": {},
   "source": [
    "To be more specific about what we want the output to look like, we need only layer additional instructions in the prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a542f651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hook: Immerse yourself in a seamless audio experience.\n",
      "\n",
      "Solution: Introducing the latest wireless earbuds, designed to revolutionize your daily listening routine.\n",
      "\n",
      "Features and Benefits:\n",
      "- **True Wireless Freedom:** No more tangled wires! Enjoy the convenience of a truly wireless design, allowing unrestricted movement during workouts, commutes, or daily activities.\n",
      "- **Crystal Clear Audio:** Experience rich, high-fidelity sound with powerful bass and crisp treble. These earbuds ensure an immersive audio experience for your favorite music, podcasts, and calls.\n",
      "- **Long-Lasting Battery:** Say goodbye to frequent charging. The earbuds offer an extended playtime of up to 8 hours on a single charge, with an additional 24 hours provided by the compact charging case.\n",
      "- **Quick and Easy Connectivity:** Seamlessly connect to your devices with Bluetooth 5.0 technology. Fast pairing ensures you can start listening in seconds.\n",
      "\n",
      "Call to Action: Upgrade your audio lifestyle. Order now and enjoy the ultimate wireless listening experience with unmatched comfort and exceptional sound quality!"
     ]
    }
   ],
   "source": [
    "generate_text(\"\"\"\n",
    "    Generate a concise product description for the product: wireless earbuds. \n",
    "    Use the following format: Hook, Solution, Features and Benefits, Call to Action.\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a9a6ae",
   "metadata": {},
   "source": [
    "## How to Add Context to a Prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a9c3fe",
   "metadata": {},
   "source": [
    "The prompt can also be constructed as a combination of an instruction and some context. In the next example, the context is an email."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b5278a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The email expresses gratitude to the team for their successful organization of a community meetup, highlighting their hard work, dedication, and invaluable contributions."
     ]
    }
   ],
   "source": [
    "generate_text(\"\"\"\n",
    "    Summarize this email in one sentence.\n",
    "    Dear [Team Members],\n",
    "    I am writing to thank you for your hard work and dedication in organizing our recent community meetup. The event was a great success and it would not have been possible without your efforts.\n",
    "    I am especially grateful for the time and energy you have invested in making this event a reality. Your commitment to ensuring that everything ran smoothly and that our guests had a great time is greatly appreciated.\n",
    "    I am also thankful for the support and guidance you have provided to me throughout the planning process. Your insights and ideas have been invaluable in ensuring that the event was a success.\n",
    "    I am confident that our community will benefit greatly from this event and I am excited to see the positive impact it will have.\n",
    "    Thank you again for your hard work and dedication. I am looking forward to working with you on future events.\n",
    "    Sincerely,\n",
    "    [Your Name]\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ababe9",
   "metadata": {},
   "source": [
    "This instruction–context prompt format is extremely useful as it means we can supply additional information as context to help ground the model's output. One example is a question-answering system for a company's knowledge base. Given a question (the instruction), the model will only be able to provide accurate answers if provided with the knowledge base (the context)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611b2e41",
   "metadata": {},
   "source": [
    "## How to Extract Information\n",
    "\n",
    "Let's move to another example—an extraction task, which involves retrieving specific information from a given larger body of text. \n",
    "\n",
    "Given context, which in this case is a description of a movie, we want the model to extract the movie title. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a671108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The movie title is \"Deadpool 2\"."
     ]
    }
   ],
   "source": [
    "generate_text(\"\"\"\n",
    "    Extract the movie title from the text below.\n",
    "    Deadpool 2 | Official HD Deadpool's \"Wet on Wet\" Teaser | 2018\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70f8e69",
   "metadata": {},
   "source": [
    "## How to Rewrite Text into Another Format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab2d13a",
   "metadata": {},
   "source": [
    "The model is also effective at tasks that involve taking a piece of text and rewriting it into another format that we need.\n",
    "\n",
    "In the next example, we have a one-line instruction followed by the context, which in this case is a blog excerpt. The instruction is to generate a list of frequently asked questions (FAQ) based on the passage, which involves a mixture of several tasks such as extraction and rewriting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83f9631e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a list of potential FAQs based on the provided text:\n",
      "\n",
      "**Q: What is the Cohere Platform?**\n",
      "A: The Cohere Platform is an API-based service that enables developers and organizations to utilize advanced Large Language Models (LLMs) without requiring expertise in machine learning. It simplifies the process of integrating cutting-edge language processing capabilities into various applications.\n",
      "\n",
      "**Q: Who is the Cohere Platform designed for?**\n",
      "A: The platform is primarily designed for developers and organizations who want to build applications or enhance their existing systems with language processing capabilities. It empowers them to focus on application development rather than the intricacies of model training and deployment.\n",
      "\n",
      "**Q: What are the main language processing capabilities offered by the Cohere Platform?**\n",
      "A: The platform provides two key capabilities: \n",
      "1. Text Generation: This allows users to input a prompt and receive a generated text completion. It can be used for creative writing, content generation, and more.\n",
      "2. Text Embedding: This capability converts textual data into numerical representations, capturing the semantic meaning of the text. It is useful for tasks like sentiment analysis, similarity search, and understanding textual data.\n",
      "\n",
      "**Q: How does text generation work?**\n",
      "A: Text generation models take a prompt as input and generate a coherent and contextually relevant completion. For example, if you prompt the model with a haiku starter, it will provide a unique haiku as the output. These models are trained on vast amounts of text data to learn patterns and generate human-like text.\n",
      "\n",
      "**Q: What are the applications of text embedding?**\n",
      "A: Text embedding is a powerful technique for transforming textual data into a numerical format that can be easily processed by machine learning algorithms. It enables various applications, including:\n",
      "- Sentiment Analysis: Identifying the sentiment (positive, negative, neutral) of customer reviews, social media posts, or feedback.\n",
      "- Semantic Search: Enabling search engines to understand the meaning of queries and retrieve relevant results.\n",
      "- Text Classification: Categorizing text documents into predefined classes or topics.\n",
      "- Similarity Matching: Finding similar documents or passages within a large corpus.\n",
      "\n",
      "**Q: Does the Cohere Platform require machine learning expertise?**\n",
      "A: No, the platform is designed to abstract away the complexities of machine learning and model development. Developers can utilize the API without needing to understand the underlying ML techniques, allowing them to focus on their application's functionality.\n",
      "\n",
      "**Q: Can you provide an example of text embedding usage?**\n",
      "A: Sure! Let's say you have a dataset of customer reviews for a product. By using text embedding, you can convert each review into a vector of numbers. You can then calculate the similarity between reviews to group positive and negative feedback, analyze common themes, or build a recommendation system based on user sentiments.\n",
      "\n",
      "**Q: How does the Cohere Platform handle data and model security?**\n",
      "A: While the text doesn't provide specific details about security measures, typically, such platforms ensure data security by employing encryption, access controls, and secure data storage practices. Model security often involves protecting model IP and ensuring that the models are not misused or accessed without proper authorization.\n",
      "\n",
      "**Q: Are there any limitations or ethical considerations when using the Cohere Platform?**\n",
      "A: As with any AI technology, there might be limitations and ethical concerns. These could include potential biases in the training data, privacy considerations when handling user-generated text, and ensuring responsible usage of the generated content. It's essential to review the platform's documentation and guidelines for a comprehensive understanding of these aspects."
     ]
    }
   ],
   "source": [
    "generate_text(\"\"\"\n",
    "    Given the following text, write down a list of potential frequently asked questions (FAQ), together with the answers.\n",
    "    The Cohere Platform provides an API for developers and organizations to access cutting-edge LLMs without needing machine learning know-how. \n",
    "    The platform handles all the complexities of curating massive amounts of text data, model development, distributed training, model serving, and more. \n",
    "    This means that developers can focus on creating value on the applied side rather than spending time and effort on the capability-building side.\n",
    "    \n",
    "    There are two key types of language processing capabilities that the Cohere Platform provides — text generation and text embedding — and each is served by a different type of model.\n",
    "    \n",
    "    With text generation, we enter a piece of text, or prompt, and get back a stream of text as a completion to the prompt. \n",
    "    One example is asking the model to write a haiku (the prompt) and getting an originally written haiku in return (the completion).\n",
    "    \n",
    "    With text embedding, we enter a piece of text and get back a list of numbers that represents its semantic meaning (we’ll see what “semantic” means in a section below). \n",
    "    This is useful for use cases that involve “measuring” what a passage of text represents, for example, in analyzing its sentiment.\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e5749d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
