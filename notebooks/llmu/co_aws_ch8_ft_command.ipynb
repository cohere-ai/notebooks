{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/cohere-ai/notebooks/blob/main/notebooks/llmu/co_aws_ch8_ft_command.ipynb\"> <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetune and deploy a custom Command-R model\n",
    "\n",
    "This sample notebook shows you how to finetune and deploy a custom Command-R model using Amazon SageMaker.\n",
    "\n",
    "> **Note**: This is a reference notebook and it cannot run unless you make changes suggested in the notebook.\n",
    "\n",
    "## Pre-requisites:\n",
    "1. **Note**: This notebook contains elements which render correctly in Jupyter interface. Open this notebook from an Amazon SageMaker Notebook Instance or Amazon SageMaker Studio.\n",
    "1. Ensure that IAM role used has **AmazonSageMakerFullAccess**\n",
    "1. To deploy this ML model successfully, ensure that:\n",
    "    1. Either your IAM role has these three permissions and you have authority to make AWS Marketplace subscriptions in the AWS account used: \n",
    "        1. **aws-marketplace:ViewSubscriptions**\n",
    "        1. **aws-marketplace:Unsubscribe**\n",
    "        1. **aws-marketplace:Subscribe**  \n",
    "    2. or your AWS account has a subscription to the packages for [Cohere Command Finetuning](TODO). If so, skip step: [Subscribe to the finetune algorithm](#1.-Subscribe-to-the-finetune-algorithm)\n",
    "\n",
    "## Contents:\n",
    "1. [Subscribe to the finetune algorithm](#1.-Subscribe-to-the-finetune-algorithm)\n",
    "2. [Upload data and finetune Command-R Model](#2.-Upload-data-and-finetune-Command-R)\n",
    "3. [Create an endpoint for inference with the custom model](#3.-Create-an-endpoint-for-inference-with-the-custom-model)\n",
    "   1. [Create an endpoint](#A.-Create-an-endpoint)\n",
    "   2. [Perform real-time inference](#B.-Perform-real-time-inference)\n",
    "4. [Clean-up](#4.-Clean-up)\n",
    "    1. [Delete the endpoint](#A.-Delete-the-endpoint)\n",
    "    2. [Unsubscribe to the listing (optional)](#Unsubscribe-to-the-listing-(optional))\n",
    "    \n",
    "\n",
    "## Usage instructions\n",
    "You can run this notebook one cell at a time (By using Shift+Enter for running a cell)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Subscribe to the finetune algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To subscribe to the model algorithm:\n",
    "1. Open the algorithm listing page [Cohere Command Finetuning](TODO)\n",
    "2. On the AWS Marketplace listing, click on the **Continue to Subscribe** button.\n",
    "3. On the **Subscribe to this software** page, review and click on **\"Accept Offer\"** if you and your organization agrees with EULA, pricing, and support terms. \n",
    "4. Once you click on **Continue to configuration** button and then choose a **region**, you will see a **Product Arn** displayed. This is the algorithm ARN that you need to specify while creating a finetune or deploying the finetuned model as an endpoint using boto3. Copy the ARN corresponding to your region and specify the same in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install cohere-aws -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from cohere_aws import Client\n",
    "import boto3\n",
    "import sagemaker as sage\n",
    "from sagemaker.s3 import S3Uploader\n",
    "\n",
    "## Set environment variables with the AWS credentials\n",
    "os.environ['AWS_ACCESS_KEY_ID'] = \"YOUR_AWS_ACCESS_KEY_ID\"\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = \"YOUR_AWS_SECRET_ACCESS_KEY\"\n",
    "os.environ['AWS_SESSION_TOKEN'] = \"YOUR_AWS_SESSION_TOKEN\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The algorithm is available in the list of AWS regions specified below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "region = boto3.Session().region_name\n",
    "\n",
    "cohere_package = \"cohere-command-r-ft-v-0-1-2-bae2282f0f4a30bca8bc6fea9efeb7ca\"\n",
    "\n",
    "# Mapping for algorithms\n",
    "algorithm_map = {\n",
    "    \"us-east-1\": f\"arn:aws:sagemaker:us-east-1:865070037744:algorithm/{cohere_package}\",\n",
    "    \"us-east-2\": f\"arn:aws:sagemaker:us-east-2:057799348421:algorithm/{cohere_package}\",\n",
    "    \"us-west-2\": f\"arn:aws:sagemaker:us-west-2:594846645681:algorithm/{cohere_package}\",\n",
    "    \"eu-central-1\": f\"arn:aws:sagemaker:eu-central-1:446921602837:algorithm/{cohere_package}\",\n",
    "    \"ap-southeast-1\": f\"arn:aws:sagemaker:ap-southeast-1:192199979996:algorithm/{cohere_package}\",\n",
    "    \"ap-southeast-2\": f\"arn:aws:sagemaker:ap-southeast-2:666831318237:algorithm/{cohere_package}\",\n",
    "    \"ap-northeast-1\": f\"arn:aws:sagemaker:ap-northeast-1:977537786026:algorithm/{cohere_package}\",\n",
    "    \"ap-south-1\": f\"arn:aws:sagemaker:ap-south-1:077584701553:algorithm/{cohere_package}\",\n",
    "}\n",
    "if region not in algorithm_map.keys():\n",
    "    raise Exception(f\"Current boto3 session region {region} is not supported.\")\n",
    "\n",
    "arn = algorithm_map[region]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Upload data and finetune Command-R\n",
    "\n",
    "Select a path on S3 to store the training and evaluation datasets and update the **s3_data_dir** below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_data_dir = f\"s3://YOUR_S3_PATH\"  # Do not add a trailing slash otherwise the upload will not work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload sample training data to S3:\n",
    "\n",
    "### Note:\n",
    "\n",
    "You'll need your data in a .jsonl file that contains prompt-completion pairs as your examples. [Doc](https://docs.cohere.com/docs/chat-preparing-the-data?_gl=1*1e7yk91*_gcl_au*MTI2MjAwNTE3Ni4xNzExNjQ3Mjgx*_ga*MTU3OTEwNjY0MC4xNjk2MDIxNjA4*_ga_CRGS116RZS*MTcxNDA4NTk4OS40OTIuMS4xNzE0MDg2MDM1LjE0LjAuMA..#data-requirements)\n",
    "\n",
    "\n",
    "### Example:\n",
    "\n",
    "JSONL:\n",
    "```\n",
    "{'messages': \n",
    " [{'role': 'System',\n",
    "   'content': 'You are a chatbot trained to answer to my every question.'\n",
    "  },\n",
    "  {'role': 'User',\n",
    "   'content': 'Hello'\n",
    "  },\n",
    "  {'role': 'Chatbot',\n",
    "   'content': 'Greetings! How can I help you?'\n",
    "  },\n",
    "\t{'role': 'User',\n",
    "   'content': 'What makes a good running route?'\n",
    "  },\n",
    "  {'role': 'Chatbot',\n",
    "   'content': 'A sidewalk-lined road is ideal so that you’re up and off the road away from vehicular traffic.'\n",
    "  }\n",
    " ]\n",
    "}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = sage.Session()\n",
    "# TODO[Optional]: change it to your data\n",
    "train_dataset = S3Uploader.upload(\"./sample_finetune_scienceQA_train.jsonl\", s3_data_dir, sagemaker_session=sess)\n",
    "eval_dataset = S3Uploader.upload(\"./sample_finetune_scienceQA_eval.jsonl\", s3_data_dir, sagemaker_session=sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Repeat the for the same for the evaluation dataset if you have one. If absent, we will auto-split the training dataset into training and evaluation datasets with the ratio of 80:20.\n",
    "\n",
    "Remember the dataset must contain at least 32 examples. If an evaluation dataset is provided, both training and evaluation datasets must contain at least 16 examples. The above split ratio is overwritten if the evaluation split is lesser than 16 examples. So for a dataset of size 50 the evaluation is 16 examples and the remaining 34 examples are used for training.\n",
    "\n",
    "We recommend using a dataset than contains at least 100 examples but a larger dataset is likely to yield high quality finetunes. Be aware that a larger dataset would mean that the time to finetune would also be longer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify a directory on S3 where finetuned models should be stored. Make sure you *do not reuse the same directory* across multiple runs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO update this with a custom S3 path\n",
    "# DO NOT re-use the same s3 directory for multiple finetunes\n",
    "# DO NOT add a trailing slash at the end\n",
    "s3_models_dir = f\"s3://YOUR_S3_PATH\"  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Cohere client:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "co = Client(region_name=region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optional: Define hyperparameters\n",
    "\n",
    "- `train_epochs`: This is the maximum number of training epochs to run for. Defaults to **1**.\n",
    "| Default | Min | Max |\n",
    "| --- | --- | --- |\n",
    "| 1 | 1 | 10 |\n",
    "- `learning_rate`: The initial learning rate to be used during training. Default to **0.01**\n",
    "| Default | Min | Max |\n",
    "| --- | --- | --- |\n",
    "| 0.01 | 0.000005 | 0.1 |\n",
    "- `train_batch_size`: The batch size used during training. Defaults to **16** for Command.\n",
    "| Default | Min | Max |\n",
    "| --- | --- | --- |\n",
    "| 16 | 8 | 32 |\n",
    "- `early_stopping_patience`: Stop training if the loss metric does not improve beyond 'early_stopping_threshold' for this many times of evaluation. Defaults to **10**\n",
    "| Default | Min | Max |\n",
    "| --- | --- | --- |\n",
    "| 10 | 1 | 15 |\n",
    "- `early_stopping_threshold`: How much the loss must improve to prevent early stopping. Defaults to **0.001**.\n",
    "| Default | Min | Max |\n",
    "| --- | --- | --- |\n",
    "| 0.001 | 0.001 | 0.1 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of how to pass hyperparameters to the fine-tuning job\n",
    "train_parameters = {\n",
    "    \"train_epochs\": 1,\n",
    "    \"early_stopping_enabled\": False,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create fine-tuning jobs for the uploaded datasets. Add a field for `eval_data` if you have pre-split your dataset and uploaded both training and evaluation datasets to S3. Remember to use p4de for Command-R Finetuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: cohere-command-R-ft-v-0-1-1-2024-05-07-04-45-52-979\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-07 04:45:53 Starting - Starting the training job...\n",
      "2024-05-07 04:46:01 Pending - Training job waiting for capacity...\n",
      "2024-05-07 04:46:39 Pending - Preparing the instances for training........................\n",
      "2024-05-07 04:50:49 Downloading - Downloading input data........................................................................................................................................................................\n",
      "2024-05-07 05:18:40 Training - Training image download completed. Training in progress.........\u001b[34mINFO:root:Loading weights from /opt/ml/additonals3data\u001b[0m\n",
      "\u001b[34mINFO:root:[Rank 7]Finished loading all variables in 89.23 s\u001b[0m\n",
      "\u001b[34mINFO:root:[Rank 6]Finished loading all variables in 89.34 s\u001b[0m\n",
      "\u001b[34mINFO:root:[Rank 2]Finished loading all variables in 90.56 s\u001b[0m\n",
      "\u001b[34mINFO:root:[Rank 5]Finished loading all variables in 89.63 s\u001b[0m\n",
      "\u001b[34mINFO:root:[Rank 1]Finished loading all variables in 91.93 s\u001b[0m\n",
      "\u001b[34mINFO:root:[Rank 0]Finished loading all variables in 89.76 s\u001b[0m\n",
      "\u001b[34mINFO:root:[Rank 4]Finished loading all variables in 90.22 s\u001b[0m\n",
      "\u001b[34mINFO:root:[Rank 3]Finished loading all variables in 94.28 s\u001b[0m\n",
      "\u001b[34mINFO:root:Finished assigning 646 variables from checkpoint\u001b[0m\n",
      "\u001b[34mINFO:root:Trainable params: 194560, Non trainable params: 4636421376\u001b[0m\n",
      "\u001b[34mINFO:root:Weights loaded from /opt/ml/additonals3data\u001b[0m\n",
      "\u001b[34mINFO:root:After removing empty, NA and duplicate documents: 5262\u001b[0m\n",
      "\u001b[34mINFO:root:After removing empty, NA and duplicate documents: 1901\u001b[0m\n",
      "\u001b[34mINFO:root:Finished step 1, train loss: 0.714844,  step time: 10.336927s\u001b[0m\n",
      "\u001b[34mINFO:root:Finished step 2, train loss: 0.204102,  step time: 6.781313s\u001b[0m\n",
      "\u001b[34mINFO:root:Finished step 3, train loss: 0.208984,  step time: 6.751096s\u001b[0m\n",
      "\u001b[34mINFO:root:Finished step 4, train loss: 0.126953,  step time: 6.754856s\u001b[0m\n",
      "\u001b[34mINFO:root:Finished step 5, train loss: 0.182617,  step time: 6.749898s\u001b[0m\n",
      "\u001b[34mINFO:root:Finished step 6, train loss: 0.124023,  step time: 6.750475s\u001b[0m\n",
      "\u001b[34mINFO:root:Finished step 7, train loss: 0.132812,  step time: 6.743358s\u001b[0m\n",
      "\u001b[34mINFO:root:Finished step 8, train loss: 0.134766,  step time: 6.948356s\u001b[0m\n",
      "\u001b[34mINFO:root:Finished step 9, train loss: 0.120117,  step time: 6.746192s\u001b[0m\n",
      "\u001b[34mINFO:root:Finished step 10, train loss: 0.134766,  step time: 6.750047s\u001b[0m\n",
      "\u001b[34mINFO:root:Finished step 11, train loss: 0.142578,  step time: 6.737731s\u001b[0m\n",
      "\u001b[34mINFO:root:Finished step 12, train loss: 0.190430,  step time: 6.743964s\u001b[0m\n",
      "\u001b[34mINFO:root:Finished step 13, train loss: 0.109863,  step time: 6.748515s\u001b[0m\n",
      "\u001b[34mINFO:root:Finished step 148, train loss: 0.113281,  step time: 6.784575s\u001b[0m\n",
      "\u001b[34mINFO:root:Finished step 149, train loss: 0.082520,  step time: 6.785972s\u001b[0m\n",
      "\u001b[34mINFO:root:Finished step 150, train loss: 0.111328,  step time: 6.970726s\u001b[0m\n",
      "\u001b[34mINFO:root:Finished step 151, train loss: 0.089844,  step time: 6.780622s\u001b[0m\n",
      "\u001b[34mINFO:root:Finished step 152, train loss: 0.070312,  step time: 6.781899s\u001b[0m\n",
      "\u001b[34mINFO:root:Finished step 153, train loss: 0.109375,  step time: 6.782448s\u001b[0m\n",
      "\u001b[34mINFO:root:Finished step 154, train loss: 0.071777,  step time: 6.780784s\u001b[0m\n",
      "\u001b[34mINFO:root:Finished step 155, train loss: 0.068359,  step time: 6.777630s\u001b[0m\n",
      "\u001b[34mINFO:root:Finished step 156, train loss: 0.050049,  step time: 6.941135s\u001b[0m\n",
      "\u001b[34mINFO:root:Finished step 157, train loss: 0.070801,  step time: 6.774098s\u001b[0m\n",
      "\u001b[34mINFO:root:Finished step 158, train loss: 0.107422,  step time: 6.972581s\u001b[0m\n",
      "\u001b[34mINFO:root:Finished step 159, train loss: 0.072754,  step time: 6.774719s\u001b[0m\n",
      "\u001b[34mINFO:root:Finished step 160, train loss: 0.032715,  step time: 6.775016s\u001b[0m\n",
      "\u001b[34mINFO:root:Exporting finished.\u001b[0m\n",
      "\u001b[34mINFO:root:Model weights exported at /opt/ml/model/finetune/export_test-scienceQA in 135.482641s\u001b[0m\n",
      "\n",
      "2024-05-07 05:57:48 Uploading - Uploading generated training model\n",
      "2024-05-07 05:59:24 Completed - Training job completed\n",
      "Training seconds: 4114\n",
      "Billable seconds: 4114\n"
     ]
    }
   ],
   "source": [
    "finetune_name = \"test-scienceQA\"\n",
    "co.create_finetune(arn=arn,\n",
    "    name=finetune_name,\n",
    "    train_data=train_dataset,\n",
    "    eval_data=eval_dataset,\n",
    "    s3_models_dir=s3_models_dir,\n",
    "    instance_type=\"ml.p4de.24xlarge\",\n",
    "    training_parameters=train_parameters\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The finetuned weights for the above will be store in a tar file `{s3_models_dir}/sample-finetune.tar.gz` where the file name is the same as the name used during the creation of the finetune."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create an endpoint for inference with the custom model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Create an endpoint\n",
    "\n",
    "The Cohere AWS SDK provides a built-in method for creating an endpoint for inference. This will automatically deploy the model you finetuned earlier.\n",
    "\n",
    "> **Note**: This is equivalent to creating and deploying a `ModelPackage` in SageMaker's SDK.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_name=\"command-finetune-test-scienceQA\"\n",
    "co.create_endpoint(arn=arn,\n",
    "        endpoint_name=endpoint_name,\n",
    "        s3_models_dir=s3_models_dir,\n",
    "        recreate=True,\n",
    "        instance_type=\"ml.p4de.24xlarge\")\n",
    "\n",
    "# If the endpoint is already created, you just need to connect to it\n",
    "# co.connect_to_endpoint(endpoint_name=endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Perform real-time inference\n",
    "\n",
    "Now, you can access all models deployed on the endpoint for inference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cohere.Chat {\n",
      "\tresponse_id: ba6be7d5-0509-4038-adfb-7de695c264b0\n",
      "\tgeneration_id: 3b509b4f-b6b3-4eee-ae5d-ccb5e46f8822\n",
      "\ttext: C\n",
      "\tchat_history: [{'role': 'USER', 'message': 'Select the best estimate.\\nQuestion: How long is a guitar?\\nOptions:(A) 32 feet (B) 32 yards (C) 32 inches (D) 32 miles\\nAnswer:'}, {'role': 'CHATBOT', 'message': 'C'}]\n",
      "\tpreamble: None\n",
      "\tfinish_reason: COMPLETE\n",
      "\ttoken_count: None\n",
      "\ttool_calls: None\n",
      "\tcitations: None\n",
      "\tdocuments: None\n",
      "\tsearch_results: None\n",
      "\tsearch_queries: None\n",
      "\tis_search_required: None\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "message = \"Select the best estimate.\\nQuestion: How long is a guitar?\\nOptions:(A) 32 feet (B) 32 yards (C) 32 inches (D) 32 miles\\nAnswer:\"\n",
    "\n",
    "result = co.chat(message=message, return_prompt=True)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's evaluate our finetuned model using the evaluation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2095/2095 [01:35<00:00, 21.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of finetuned model is 0.8310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "total = 0\n",
    "correct = 0\n",
    "for line in tqdm(open('./sample_finetune_scienceQA_eval.jsonl').readlines()):\n",
    "    total += 1\n",
    "    question_answer_json = json.loads(line)\n",
    "    question = question_answer_json[\"messages\"][0][\"content\"]\n",
    "    answer = question_answer_json[\"messages\"][1][\"content\"]\n",
    "    model_ans = co.chat(message=question, temperature=0, k=1).text\n",
    "    if model_ans == answer:\n",
    "        correct +=1\n",
    "\n",
    "print(f\"Accuracy of finetuned model is %.4f\" % (correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Clean-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Delete the endpoint\n",
    "\n",
    "After you've successfully performed inference, you can delete the deployed endpoint to avoid being charged continuously. This can also be done via the Cohere AWS SDK:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "co.delete_endpoint()\n",
    "co.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsubscribe to the listing (optional)\n",
    "\n",
    "If you would like to unsubscribe to the model package, follow these steps. Before you cancel the subscription, ensure that you do not have any [deployable models](https://console.aws.amazon.com/sagemaker/home#/models) created from the model package or using the algorithm. Note - You can find this information by looking at the container name associated with the model. \n",
    "\n",
    "**Steps to unsubscribe to product from AWS Marketplace**:\n",
    "1. Navigate to __Machine Learning__ tab on [__Your Software subscriptions page__](https://aws.amazon.com/marketplace/ai/library?productType=ml&ref_=mlmp_gitdemo_indust)\n",
    "2. Locate the listing that you want to cancel the subscription for, and then choose __Cancel Subscription__  to cancel the subscription.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "3b57b3736fb00bc0deb03789040183ddbda4c9eb8e8f6bef7ea4333bc64826af"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
