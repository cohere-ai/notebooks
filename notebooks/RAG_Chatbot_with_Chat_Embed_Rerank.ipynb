{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to Build a RAG-Powered Chatbot with Chat, Embed, and Rerank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Read the accompanying [blog post here](https://txt.cohere.com/rag-chatbot).*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Feature](images/rag-chatbot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, you’ll learn how to build a chatbot that has RAG capabilities, enabling it to connect to external documents, ground its responses on these documents, and produce document citations in its responses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a diagram that provides an overview of what we’ll build, followed by a list of the key steps involved.\n",
    "\n",
    "![Overview](images/rag-chatbot-flow.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup phase:\n",
    "- Step 0: Ingest the documents – get documents, chunk, embed, and index.\n",
    "\n",
    "For each user-chatbot interaction:\n",
    "- Step 1: Get the user message\n",
    "- Step 2: Call the Chat endpoint in query-generation mode\n",
    "- If at least one query is generated\n",
    "    - Step 3: Retrieve and rerank relevant documents\n",
    "    - Step 4: Call the Chat endpoint in document mode to generate a grounded response with citations\n",
    "- If no query is generated\n",
    "    - Step 4: Call the Chat endpoint in normal mode to generate a response\n",
    "\n",
    "Throughout the conversation:\n",
    "- Append the user-chatbot interaction to the conversation thread\n",
    "- Repeat with every interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install cohere hnswlib unstructured -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cohere\n",
    "import os\n",
    "import hnswlib\n",
    "import json\n",
    "import uuid\n",
    "from typing import List, Dict\n",
    "from unstructured.partition.html import partition_html\n",
    "from unstructured.chunking.title import chunk_by_title\n",
    "\n",
    "co = cohere.Client(os.environ[\"COHERE_API_KEY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Enable text wrapping in Google colab\n",
    "\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "def set_css():\n",
    "  display(HTML('''\n",
    "  <style>\n",
    "    pre {\n",
    "        white-space: pre-wrap;\n",
    "    }\n",
    "  </style>\n",
    "  '''))\n",
    "get_ipython().events.register('pre_run_cell', set_css)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Documents component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class Documents:\n",
    "    \"\"\"\n",
    "    A class representing a collection of documents.\n",
    "\n",
    "    Parameters:\n",
    "    sources (list): A list of dictionaries representing the sources of the documents. Each dictionary should have 'title' and 'url' keys.\n",
    "\n",
    "    Attributes:\n",
    "    sources (list): A list of dictionaries representing the sources of the documents.\n",
    "    docs (list): A list of dictionaries representing the documents, with 'title', 'content', and 'url' keys.\n",
    "    docs_embs (list): A list of the associated embeddings for the documents.\n",
    "    retrieve_top_k (int): The number of documents to retrieve during search.\n",
    "    rerank_top_k (int): The number of documents to rerank after retrieval.\n",
    "    docs_len (int): The number of documents in the collection.\n",
    "    index (hnswlib.Index): The index used for document retrieval.\n",
    "\n",
    "    Methods:\n",
    "    load(): Loads the data from the sources and partitions the HTML content into chunks.\n",
    "    embed(): Embeds the documents using the Cohere API.\n",
    "    index(): Indexes the documents for efficient retrieval.\n",
    "    retrieve(query): Retrieves documents based on the given query.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, sources: List[Dict[str, str]]):\n",
    "        self.sources = sources\n",
    "        self.docs = []\n",
    "        self.docs_embs = []\n",
    "        self.retrieve_top_k = 10\n",
    "        self.rerank_top_k = 3\n",
    "        self.load()\n",
    "        self.embed()\n",
    "        self.index()\n",
    "\n",
    "    def load(self) -> None:\n",
    "        \"\"\"\n",
    "        Loads the documents from the sources and chunks the HTML content.\n",
    "        \"\"\"\n",
    "        print(\"Loading documents...\")\n",
    "\n",
    "        for source in self.sources:\n",
    "            elements = partition_html(url=source[\"url\"])\n",
    "            chunks = chunk_by_title(elements)\n",
    "            for chunk in chunks:\n",
    "                self.docs.append(\n",
    "                    {\n",
    "                        \"title\": source[\"title\"],\n",
    "                        \"text\": str(chunk),\n",
    "                        \"url\": source[\"url\"],\n",
    "                    }\n",
    "                )\n",
    "\n",
    "    def embed(self) -> None:\n",
    "        \"\"\"\n",
    "        Embeds the documents using the Cohere API.\n",
    "        \"\"\"\n",
    "        print(\"Embedding documents...\")\n",
    "\n",
    "        batch_size = 90\n",
    "        self.docs_len = len(self.docs)\n",
    "\n",
    "        for i in range(0, self.docs_len, batch_size):\n",
    "            batch = self.docs[i : min(i + batch_size, self.docs_len)]\n",
    "            texts = [item[\"text\"] for item in batch]\n",
    "            docs_embs_batch = co.embed(\n",
    "                texts=texts, model=\"embed-english-v3.0\", input_type=\"search_document\"\n",
    "            ).embeddings\n",
    "            self.docs_embs.extend(docs_embs_batch)\n",
    "\n",
    "    def index(self) -> None:\n",
    "        \"\"\"\n",
    "        Indexes the documents for efficient retrieval.\n",
    "        \"\"\"\n",
    "        print(\"Indexing documents...\")\n",
    "\n",
    "        self.idx = hnswlib.Index(space=\"ip\", dim=1024)\n",
    "        self.idx.init_index(max_elements=self.docs_len, ef_construction=512, M=64)\n",
    "        self.idx.add_items(self.docs_embs, list(range(len(self.docs_embs))))\n",
    "\n",
    "        print(f\"Indexing complete with {self.idx.get_current_count()} documents.\")\n",
    "\n",
    "    def retrieve(self, query: str) -> List[Dict[str, str]]:\n",
    "        \"\"\"\n",
    "        Retrieves documents based on the given query.\n",
    "\n",
    "        Parameters:\n",
    "        query (str): The query to retrieve documents for.\n",
    "\n",
    "        Returns:\n",
    "        List[Dict[str, str]]: A list of dictionaries representing the retrieved documents, with 'title', 'text', and 'url' keys.\n",
    "        \"\"\"\n",
    "        docs_retrieved = []\n",
    "        query_emb = co.embed(\n",
    "            texts=[query], model=\"embed-english-v3.0\", input_type=\"search_query\"\n",
    "        ).embeddings\n",
    "\n",
    "        doc_ids = self.idx.knn_query(query_emb, k=self.retrieve_top_k)[0][0]\n",
    "\n",
    "        docs_to_rerank = []\n",
    "        for doc_id in doc_ids:\n",
    "            docs_to_rerank.append(self.docs[doc_id][\"text\"])\n",
    "\n",
    "        rerank_results = co.rerank(\n",
    "            query=query,\n",
    "            documents=docs_to_rerank,\n",
    "            top_n=self.rerank_top_k,\n",
    "            model=\"rerank-english-v2.0\",\n",
    "        )\n",
    "\n",
    "        doc_ids_reranked = []\n",
    "        for result in rerank_results:\n",
    "            doc_ids_reranked.append(doc_ids[result.index])\n",
    "\n",
    "        for doc_id in doc_ids_reranked:\n",
    "            docs_retrieved.append(\n",
    "                {\n",
    "                    \"title\": self.docs[doc_id][\"title\"],\n",
    "                    \"text\": self.docs[doc_id][\"text\"],\n",
    "                    \"url\": self.docs[doc_id][\"url\"],\n",
    "                }\n",
    "            )\n",
    "\n",
    "        return docs_retrieved"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chatbot component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class Chatbot:\n",
    "    \"\"\"\n",
    "    A class representing a chatbot.\n",
    "\n",
    "    Parameters:\n",
    "    docs (Documents): An instance of the Documents class representing the collection of documents.\n",
    "\n",
    "    Attributes:\n",
    "    conversation_id (str): The unique ID for the conversation.\n",
    "    docs (Documents): An instance of the Documents class representing the collection of documents.\n",
    "\n",
    "    Methods:\n",
    "    generate_response(message): Generates a response to the user's message.\n",
    "    retrieve_docs(response): Retrieves documents based on the search queries in the response.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, docs: Documents):\n",
    "        self.docs = docs\n",
    "        self.conversation_id = str(uuid.uuid4())\n",
    "\n",
    "    def generate_response(self, message: str):\n",
    "        \"\"\"\n",
    "        Generates a response to the user's message.\n",
    "\n",
    "        Parameters:\n",
    "        message (str): The user's message.\n",
    "\n",
    "        Yields:\n",
    "        Event: A response event generated by the chatbot.\n",
    "\n",
    "        Returns:\n",
    "        List[Dict[str, str]]: A list of dictionaries representing the retrieved documents.\n",
    "\n",
    "        \"\"\"\n",
    "        # Generate search queries (if any)\n",
    "        response = co.chat(message=message, search_queries_only=True)\n",
    "\n",
    "        # If there are search queries, retrieve documents and respond\n",
    "        if response.search_queries:\n",
    "            print(\"Retrieving information...\")\n",
    "\n",
    "            documents = self.retrieve_docs(response)\n",
    "\n",
    "            response = co.chat(\n",
    "                message=message,\n",
    "                documents=documents,\n",
    "                conversation_id=self.conversation_id,\n",
    "                stream=True,\n",
    "            )\n",
    "            for event in response:\n",
    "                yield event\n",
    "\n",
    "        # If there is no search query, directly respond\n",
    "        else:\n",
    "            response = co.chat(\n",
    "                message=message, \n",
    "                conversation_id=self.conversation_id, \n",
    "                stream=True\n",
    "            )\n",
    "            for event in response:\n",
    "                yield event\n",
    "\n",
    "    def retrieve_docs(self, response) -> List[Dict[str, str]]:\n",
    "        \"\"\"\n",
    "        Retrieves documents based on the search queries in the response.\n",
    "\n",
    "        Parameters:\n",
    "        response: The response object containing search queries.\n",
    "\n",
    "        Returns:\n",
    "        List[Dict[str, str]]: A list of dictionaries representing the retrieved documents.\n",
    "\n",
    "        \"\"\"\n",
    "        # Get the query(s)\n",
    "        queries = []\n",
    "        for search_query in response.search_queries:\n",
    "            queries.append(search_query[\"text\"])\n",
    "\n",
    "        # Retrieve documents for each query\n",
    "        retrieved_docs = []\n",
    "        for query in queries:\n",
    "            retrieved_docs.extend(self.docs.retrieve(query))\n",
    "\n",
    "        # # Uncomment this code block to display the chatbot's retrieved documents\n",
    "        # print(\"DOCUMENTS RETRIEVED:\")\n",
    "        # for idx, doc in enumerate(retrieved_docs):\n",
    "        #     print(f\"doc_{idx}: {doc}\")\n",
    "        # print(\"\\n\")\n",
    "\n",
    "        return retrieved_docs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### App component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class App:\n",
    "    def __init__(self, chatbot: Chatbot):\n",
    "        \"\"\"\n",
    "        Initializes an instance of the App class.\n",
    "\n",
    "        Parameters:\n",
    "        chatbot (Chatbot): An instance of the Chatbot class.\n",
    "\n",
    "        \"\"\"\n",
    "        self.chatbot = chatbot\n",
    "    \n",
    "    def run(self):\n",
    "        \"\"\"\n",
    "        Runs the chatbot application.\n",
    "\n",
    "        \"\"\"\n",
    "        while True:\n",
    "            # Get the user message\n",
    "            message = input(\"User: \")\n",
    "\n",
    "            # Typing \"quit\" ends the conversation\n",
    "            if message.lower() == \"quit\":\n",
    "                print(\"Ending chat.\")\n",
    "                break\n",
    "            else:\n",
    "                print(f\"User: {message}\")\n",
    "\n",
    "            # Get the chatbot response\n",
    "            response = self.chatbot.generate_response(message)\n",
    "\n",
    "            # Print the chatbot response\n",
    "            print(\"Chatbot:\")\n",
    "            flag = False\n",
    "            for event in response:\n",
    "                # Text\n",
    "                if event.event_type == \"text-generation\":\n",
    "                    print(event.text, end=\"\")\n",
    "\n",
    "                # Citations\n",
    "                if event.event_type == \"citation-generation\":\n",
    "                    if not flag:\n",
    "                        print(\"\\n\\nCITATIONS:\")\n",
    "                        flag = True\n",
    "                    print(event.citations)\n",
    "\n",
    "            print(f\"\\n{'-'*100}\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the sources for the documents\n",
    "# As an example, we'll use LLM University's Module 1: What are Large Language Models?\n",
    "# https://docs.cohere.com/docs/intro-large-language-models\n",
    "\n",
    "sources = [\n",
    "    {\n",
    "        \"title\": \"Text Embeddings\", \n",
    "        \"url\": \"https://docs.cohere.com/docs/text-embeddings\"},\n",
    "    {\n",
    "        \"title\": \"Similarity Between Words and Sentences\", \n",
    "        \"url\": \"https://docs.cohere.com/docs/similarity-between-words-and-sentences\"},\n",
    "    {\n",
    "        \"title\": \"The Attention Mechanism\", \n",
    "        \"url\": \"https://docs.cohere.com/docs/the-attention-mechanism\"},\n",
    "    {\n",
    "        \"title\": \"Transformer Models\", \n",
    "        \"url\": \"https://docs.cohere.com/docs/transformer-models\"}   \n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading documents...\n",
      "Embedding documents...\n",
      "Indexing documents...\n",
      "Indexing complete with 136 documents.\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of the Documents class with the given sources\n",
    "documents = Documents(sources)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Hi there\n",
      "Chatbot:\n",
      "Hi there! I'm Coral, an AI-assistant chatbot trained to assist human users by providing thorough responses. Is there anything I can help you with today?\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "User: What are text embeddings\n",
      "Chatbot:\n",
      "Retrieving information...\n",
      "Text embeddings are used to convert words into numbers, creating a vector of numerical data for every piece of text. If the vectors for two pieces of text are similar, this means that the corresponding pieces of text are similar too, and vice versa. Text embeddings are particularly useful for tasks like machine translation and searching for text in different languages. \n",
      "\n",
      "Would you like me to go into more detail about any of the information mentioned above?\n",
      "\n",
      "CITATIONS:\n",
      "[{'start': 28, 'end': 54, 'text': 'convert words into numbers', 'document_ids': ['doc_1']}]\n",
      "[{'start': 67, 'end': 116, 'text': 'vector of numerical data for every piece of text.', 'document_ids': ['doc_1']}]\n",
      "[{'start': 136, 'end': 166, 'text': 'two pieces of text are similar', 'document_ids': ['doc_1']}]\n",
      "[{'start': 188, 'end': 249, 'text': 'corresponding pieces of text are similar too, and vice versa.', 'document_ids': ['doc_1']}]\n",
      "[{'start': 305, 'end': 324, 'text': 'machine translation', 'document_ids': ['doc_2']}]\n",
      "[{'start': 329, 'end': 371, 'text': 'searching for text in different languages.', 'document_ids': ['doc_2']}]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "User: What are they useful for\n",
      "Chatbot:\n",
      "Retrieving information...\n",
      "Text embeddings are useful for a variety of tasks, including:\n",
      "\n",
      "- Machine learning - for example, transformer models can be used to write stories, essays and poems, as well as answer questions and chat with humans.\n",
      "- Machine translation - text embeddings can translate text from one language to another.\n",
      "- Searching for text - text embeddings can be used to find text in any language. \n",
      "\n",
      "Would you like me to go into more detail about any of the tasks text embeddings are useful for?\n",
      "\n",
      "CITATIONS:\n",
      "[{'start': 65, 'end': 81, 'text': 'Machine learning', 'document_ids': ['doc_1']}]\n",
      "[{'start': 97, 'end': 115, 'text': 'transformer models', 'document_ids': ['doc_0', 'doc_1']}]\n",
      "[{'start': 131, 'end': 144, 'text': 'write stories', 'document_ids': ['doc_0', 'doc_1']}]\n",
      "[{'start': 146, 'end': 152, 'text': 'essays', 'document_ids': ['doc_1']}]\n",
      "[{'start': 157, 'end': 162, 'text': 'poems', 'document_ids': ['doc_0', 'doc_1']}]\n",
      "[{'start': 175, 'end': 191, 'text': 'answer questions', 'document_ids': ['doc_1']}]\n",
      "[{'start': 196, 'end': 213, 'text': 'chat with humans.', 'document_ids': ['doc_1']}]\n",
      "[{'start': 216, 'end': 235, 'text': 'Machine translation', 'document_ids': ['doc_1']}]\n",
      "[{'start': 258, 'end': 302, 'text': 'translate text from one language to another.', 'document_ids': ['doc_1']}]\n",
      "[{'start': 305, 'end': 323, 'text': 'Searching for text', 'document_ids': ['doc_1']}]\n",
      "[{'start': 370, 'end': 383, 'text': 'any language.', 'document_ids': ['doc_1']}]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "User: How do you generate them\n",
      "Chatbot:\n",
      "Retrieving information...\n",
      "Text embeddings are generated by training transformer models on large datasets, such as the entire internet or large datasets of conversations. Post-training helps improve the model's performance on specific tasks by focusing on datasets corresponding to questions and answers or conversations. \n",
      "\n",
      "Would you like me to go into more detail about transformer models?\n",
      "\n",
      "CITATIONS:\n",
      "[{'start': 42, 'end': 60, 'text': 'transformer models', 'document_ids': ['doc_0', 'doc_1', 'doc_2']}]\n",
      "[{'start': 92, 'end': 107, 'text': 'entire internet', 'document_ids': ['doc_0']}]\n",
      "[{'start': 129, 'end': 143, 'text': 'conversations.', 'document_ids': ['doc_1']}]\n",
      "[{'start': 144, 'end': 195, 'text': \"Post-training helps improve the model's performance\", 'document_ids': ['doc_0', 'doc_1']}]\n",
      "[{'start': 255, 'end': 276, 'text': 'questions and answers', 'document_ids': ['doc_0']}]\n",
      "[{'start': 280, 'end': 294, 'text': 'conversations.', 'document_ids': ['doc_1']}]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Ending chat.\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of the Chatbot class with the Documents instance\n",
    "chatbot = Chatbot(documents)\n",
    "\n",
    "# Create an instance of the App class with the Chatbot instance\n",
    "app = App(chatbot)\n",
    "\n",
    "# Run the chatbot\n",
    "app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
