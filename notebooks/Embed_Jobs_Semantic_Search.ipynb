{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ig3hmpIt8ptJ"
      },
      "source": [
        "# Semantic Search with Cohere Embed Jobs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fc94ylzpucDm"
      },
      "outputs": [],
      "source": [
        "# TODO: upgrade to \"cohere>5\"\n",
        "! pip install \"cohere<5\" hnswlib -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qu9a_jwZ5Zop"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import cohere\n",
        "import hnswlib\n",
        "co = cohere.Client('COHERE_API_KEY')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fgqhh1kk8mnY"
      },
      "source": [
        "## Step 1: Upload a dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kogkZnDEnK8B",
        "outputId": "646b4508-8111-42ad-a9b2-3425da1ae5ff"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "uploading file, starting validation...\n",
            "sample-file-hca4x0 was uploaded\n",
            "...\n"
          ]
        }
      ],
      "source": [
        "# Upload a dataset for embed jobs\n",
        "# This sample dataset has wikipedia articles on the following: Youtube, United States, United Kingdom, Elizabeth II, Wikipedia, 2022 FIFA World Cup, Microsoft Office, India, Christiano Ronaldo, Cleopatra, Instagram, Facebook, and Ukraine\n",
        "\n",
        "dataset_file_path = \"data/embed_jobs_sample_data.jsonl\" # Full path - https://raw.githubusercontent.com/cohere-ai/notebooks/main/notebooks/data/embed_jobs_sample_data.jsonl\n",
        "\n",
        "ds=co.create_dataset(\n",
        "\tname='sample_file',\n",
        "\tdata=open(dataset_file_path, 'rb'),\n",
        "\tkeep_fields = ['id','wiki_id'],\n",
        "\tdataset_type=\"embed-input\"\n",
        "\t)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3lAS4bcvCplJ",
        "outputId": "5e1fcd0b-4880-43ed-d8a4-03148b2ef047"
      },
      "outputs": [],
      "source": [
        "print(ds.await_validation())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QgD2QCJk9kUN"
      },
      "source": [
        "## Step 2: Create embeddings via Cohere's Embed Jobs endpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yMYoU9y55m2D",
        "outputId": "fd58014d-a9e3-4a3f-ca4b-966880dec412"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "...\n",
            "...\n"
          ]
        }
      ],
      "source": [
        "# Dataset has been uploaded, create an embed job and specify the input type as \"search document\" since this will live in your Pinecone DB\n",
        "job = co.create_embed_job(\n",
        "    dataset_id=ds.id,\n",
        "    input_type='search_document' ,\n",
        "    model='embed-english-v3.0', \n",
        "    embeddings_types=['float'])\n",
        "\n",
        "job.wait() # poll the server until the job is completed "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LEevvN2XCUpR",
        "outputId": "d123c0a4-0c6a-4235-9ba8-658d5d3ec358"
      },
      "outputs": [],
      "source": [
        "print(job)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZVf1njJ4952G"
      },
      "source": [
        "## Step 3: Download and prepare the embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0FdyxbcR5uci"
      },
      "outputs": [],
      "source": [
        "# Save down the output of the job\n",
        "embeddings_file_path = 'embed_jobs_output.csv'\n",
        "output_dataset=co.get_dataset(job.output.id)\n",
        "output_dataset.save(filepath=embeddings_file_path, format=\"csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VvheIBdJ6FC_"
      },
      "outputs": [],
      "source": [
        "# Add the results\n",
        "embeddings=[]\n",
        "texts=[]\n",
        "for record in output_dataset:\n",
        "  embeddings.append(record['embeddings']['float'])\n",
        "  texts.append(record['text'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-O-Yz8MS-DFz"
      },
      "source": [
        "## Step 4: Initialize Hnwslib index and add embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_vGfX8aQ9uD1"
      },
      "outputs": [],
      "source": [
        "# Create the hnsw index\n",
        "index = hnswlib.Index(space='ip', dim=1024)\n",
        "index.init_index(max_elements=len(embeddings), ef_construction=512, M=64)\n",
        "index.add_items(embeddings,list(range(len(embeddings))))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yN5qBoVX-M7g"
      },
      "source": [
        "## Step 5: Query the index and rerank the results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5NWR4MJUBQHW"
      },
      "outputs": [],
      "source": [
        "# Query the Database\n",
        "query = \"What was the first youtube video about?\"\n",
        "\n",
        "# Convert the query into embeddings\n",
        "query_emb=co.embed(\n",
        "    texts=[query], model=\"embed-english-v3.0\", input_type=\"search_query\"\n",
        "        ).embeddings\n",
        "\n",
        "# Retrieve the initial results from your vector db\n",
        "doc_index = index.knn_query(query_emb, k=10)[0][0]\n",
        "\n",
        "# From the doc_index, get the text from each index and then pass the text into rerank\n",
        "docs_to_rerank = []\n",
        "for index in doc_index:\n",
        "  docs_to_rerank.append(texts[index])\n",
        "\n",
        "final_result = co.rerank(\n",
        "    query= query,\n",
        "    documents=docs_to_rerank,\n",
        "    model=\"rerank-english-v2.0\",\n",
        "    top_n=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oya4CRdE-WDU"
      },
      "source": [
        "## Step 6: Display the results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rvs0Se2wER1a",
        "outputId": "eeb3e148-af79-46c0-ca3b-ae9facde5fbc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Document Rank: 1, Document Index: 0\n",
            "Document: YouTube began as a venture capital–funded technology startup. Between November 2005 and April 2006, the company raised money from various investors, with Sequoia Capital, $11.5 million, and Artis Capital Management, $8 million, being the largest two. YouTube's early headquarters were situated above a pizzeria and a Japanese restaurant in San Mateo, California. In February 2005, the company activated codice_1. The first video was uploaded April 23, 2005. Titled \"Me at the zoo\", it shows co-founder Jawed Karim at the San Diego Zoo and can still be viewed on the site. In May, the company launched a public beta and by November, a Nike ad featuring Ronaldinho became the first video to reach one million total views. The site launched officially on December 15, 2005, by which time the site was receiving 8 million views a day. Clips at the time were limited to 100 megabytes, as little as 30 seconds of footage.\n",
            "Relevance Score: 0.94815\n",
            "\n",
            "\n",
            "Document Rank: 2, Document Index: 1\n",
            "Document: Karim said the inspiration for YouTube first came from the Super Bowl XXXVIII halftime show controversy when Janet Jackson's breast was briefly exposed by Justin Timberlake during the halftime show. Karim could not easily find video clips of the incident and the 2004 Indian Ocean Tsunami online, which led to the idea of a video-sharing site. Hurley and Chen said that the original idea for YouTube was a video version of an online dating service, and had been influenced by the website Hot or Not. They created posts on Craigslist asking attractive women to upload videos of themselves to YouTube in exchange for a $100 reward. Difficulty in finding enough dating videos led to a change of plans, with the site's founders deciding to accept uploads of any video.\n",
            "Relevance Score: 0.91626\n",
            "\n",
            "\n",
            "Document Rank: 3, Document Index: 2\n",
            "Document: YouTube was not the first video-sharing site on the Internet; Vimeo was launched in November 2004, though that site remained a side project of its developers from CollegeHumor at the time and did not grow much, either. The week of YouTube's launch, NBC-Universal's \"Saturday Night Live\" ran a skit \"Lazy Sunday\" by The Lonely Island. Besides helping to bolster ratings and long-term viewership for \"Saturday Night Live\", \"Lazy Sunday\"'s status as an early viral video helped establish YouTube as an important website. Unofficial uploads of the skit to YouTube drew in more than five million collective views by February 2006 before they were removed when NBCUniversal requested it two months later based on copyright concerns. Despite eventually being taken down, these duplicate uploads of the skit helped popularize YouTube's reach and led to the upload of more third-party content. The site grew rapidly; in July 2006, the company announced that more than 65,000 new videos were being uploaded every day and that the site was receiving 100 million video views per day.\n",
            "Relevance Score: 0.90665\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Output Results\n",
        "for idx, r in enumerate(final_result):\n",
        "  print(f\"Document Rank: {idx + 1}, Document Index: {r.index}\")\n",
        "  print(f\"Document: {r.document['text']}\")\n",
        "  print(f\"Relevance Score: {r.relevance_score:.5f}\")\n",
        "  print(\"\\n\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
